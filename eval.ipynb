{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pelinski/opt/anaconda3/envs/rhythm/lib/python2.7/site-packages/h5py/__init__.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/pelinski/opt/anaconda3/envs/rhythm/lib/python2.7/site-packages/h5py/__init__.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import h5a, h5d, h5ds, h5f, h5fd, h5g, h5r, h5s, h5t, h5p, h5z\n",
      "/Users/pelinski/opt/anaconda3/envs/rhythm/lib/python2.7/site-packages/h5py/_hl/group.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .. import h5g, h5i, h5o, h5r, h5t, h5l, h5p\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('models')\n",
    "from large_vocab_adt_dafx2018.transcribe import transcribe, PERC_VOICE_SET\n",
    "import large_vocab_adt_dafx2018.model as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drummer</th>\n",
       "      <th>session</th>\n",
       "      <th>id</th>\n",
       "      <th>style</th>\n",
       "      <th>bpm</th>\n",
       "      <th>beat_type</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>midi_filename</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>duration</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/1</td>\n",
       "      <td>funk/groove1</td>\n",
       "      <td>138</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
       "      <td>27.872308</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/10</td>\n",
       "      <td>soul/groove10</td>\n",
       "      <td>102</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
       "      <td>37.691158</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/2</td>\n",
       "      <td>funk/groove2</td>\n",
       "      <td>105</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
       "      <td>36.351218</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/3</td>\n",
       "      <td>soul/groove3</td>\n",
       "      <td>86</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
       "      <td>44.716543</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drummer1</td>\n",
       "      <td>drummer1/eval_session</td>\n",
       "      <td>drummer1/eval_session/4</td>\n",
       "      <td>soul/groove4</td>\n",
       "      <td>80</td>\n",
       "      <td>beat</td>\n",
       "      <td>4-4</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
       "      <td>47.987500</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    drummer                session                        id          style  \\\n",
       "0  drummer1  drummer1/eval_session   drummer1/eval_session/1   funk/groove1   \n",
       "1  drummer1  drummer1/eval_session  drummer1/eval_session/10  soul/groove10   \n",
       "2  drummer1  drummer1/eval_session   drummer1/eval_session/2   funk/groove2   \n",
       "3  drummer1  drummer1/eval_session   drummer1/eval_session/3   soul/groove3   \n",
       "4  drummer1  drummer1/eval_session   drummer1/eval_session/4   soul/groove4   \n",
       "\n",
       "   bpm beat_type time_signature  \\\n",
       "0  138      beat            4-4   \n",
       "1  102      beat            4-4   \n",
       "2  105      beat            4-4   \n",
       "3   86      beat            4-4   \n",
       "4   80      beat            4-4   \n",
       "\n",
       "                                       midi_filename  \\\n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...   \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...   \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...   \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...   \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...   \n",
       "\n",
       "                                      audio_filename   duration split  \n",
       "0  drummer1/eval_session/1_funk-groove1_138_beat_...  27.872308  test  \n",
       "1  drummer1/eval_session/10_soul-groove10_102_bea...  37.691158  test  \n",
       "2  drummer1/eval_session/2_funk-groove2_105_beat_...  36.351218  test  \n",
       "3  drummer1/eval_session/3_soul-groove3_86_beat_4...  44.716543  test  \n",
       "4  drummer1/eval_session/4_soul-groove4_80_beat_4...  47.987500  test  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# files in dataset\n",
    "import pandas as pd\n",
    "\n",
    "groove_path = 'groove/'\n",
    "\n",
    "# load info from dataset\n",
    "magenta_ds = pd.read_csv('groove/info.csv')\n",
    "\n",
    "# remove rows without wav file\n",
    "magenta_ds = magenta_ds.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False) \n",
    "\n",
    "magenta_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mir_eval\n",
    "\n",
    "def compute_scores(magenta_transcription, out_8v_thres,instrument_index):\n",
    "\n",
    "    onsets_eval_magenta = np.arange(magenta_transcription.shape[0])*magenta_transcription[:,instrument_index]*0.01 \n",
    "    onsets_eval_magenta = np.sort(onsets_eval_magenta[onsets_eval_magenta!=0])\n",
    "\n",
    "    onsets_eval_model = np.arange(out_8v_thres.shape[0])*out_8v_thres[:,instrument_index]*0.01\n",
    "    onsets_eval_model = np.sort(onsets_eval_model[onsets_eval_model!=0])\n",
    "\n",
    "\n",
    "    #print(onsets_eval_magenta[0:5])\n",
    "    #print(np.round(onsets_eval_model[0:5],2))\n",
    "    #print(len(onsets_eval_model),len(onsets_eval_magenta))\n",
    "\n",
    "    # mir_eval: \n",
    "    # Onsets should be provided in the form of a 1-dimensional array of onset \n",
    "    # times in seconds in increasing order.\n",
    "    # default window is 0.05 seconds !! CHOICE OF WINDOW IS CRUCIAL\n",
    "    # same value as in paper\n",
    "    mir_eval.onset.validate(onsets_eval_magenta,onsets_eval_model)\n",
    "    scores = mir_eval.onset.f_measure(onsets_eval_magenta,onsets_eval_model, window=0.5)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_onsets(input_audio_file, model_num=303):\n",
    "    \n",
    "    models_path = 'models/large_vocab_adt_dafx2018/trained_models/'\n",
    "\n",
    "    # load model\n",
    "    model_definition_path = os.path.join(models_path,str(model_num)+'_s0_def.json')\n",
    "    model_weights_path = os.path.join(models_path,str(model_num)+'_s0_weights.h5')\n",
    "    model_configuration_id = model_num\n",
    "    sample_audio_files = dict([(v, os.path.join('models/audio/', '{}.wav'.format(v))) for v in PERC_VOICE_SET])\n",
    "\n",
    "\n",
    "    # compute model's onsets >> outputs 14 voices\n",
    "    output = transcribe(model_definition_path,\n",
    "                    model_weights_path,\n",
    "                    input_audio_file,\n",
    "                    model_configuration_id,\n",
    "                    sample_audio_files,\n",
    "                    peak_params=None,\n",
    "                    output_sample_rate=44100)\n",
    "\n",
    "    # save into out_14v\n",
    "    out_14v = output['14v']['onset_activations']\n",
    "    \n",
    "    # reduce 14 voices to the 8 present in the magenta dataset\n",
    "    length_in_samples = out_14v.shape[0]\n",
    "    out_8v = np.zeros([length_in_samples,8])\n",
    "\n",
    "    reduced_mapping = {\n",
    "    0: [0],     # kick\n",
    "    1: [1,2],   # snare + snare rim \n",
    "    2: [3],     # crash\n",
    "    3: [4,12],  # ride + bell\n",
    "    4: [5],     # open hh\n",
    "    5: [6],     # closed hh\n",
    "    6: [7,8],   # low+mid tom\n",
    "    7: [9]      # high tom\n",
    "    }\n",
    "\n",
    "\n",
    "    eps = 0 # threshold ?\n",
    "\n",
    "    for t in range(length_in_samples):\n",
    "        t_roll = out_14v[t,:]\n",
    "        t_roll[t_roll<eps] = 0\n",
    "        for i in reduced_mapping.keys():\n",
    "            out_8v[t,i] = np.max(t_roll[reduced_mapping[i]])\n",
    "    \n",
    "    return out_8v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "\n",
    "def get_magenta_onsets(input_midi_file):\n",
    "    # read with prettyMIDI\n",
    "    midi_data = pretty_midi.PrettyMIDI(input_midi_file)\n",
    "        \n",
    "    length_in_samples = int(midi_data.get_end_time()/0.01)\n",
    "\n",
    "    # extract onsets from midi file with midi_data.get_onsets()\n",
    "    onsets = midi_data.get_onsets()\n",
    "    \n",
    "    # get pretty_midi Notes objects in a list\n",
    "    drums_notes = midi_data.instruments[0].notes[:]\n",
    "    \n",
    "    # initiate drum_onsets and instruments array\n",
    "    drums_onsets = []\n",
    "    drums_instrument = []\n",
    "    \n",
    "    # fill with info from prettymidi notes objects\n",
    "    for note in drums_notes:\n",
    "        drums_onsets.append(note.start)    # onsets list\n",
    "        drums_instrument.append(note.pitch)   # instrument  \n",
    "    \n",
    "    # transform onsets to seconds\n",
    "    drums_onsets = np.round(drums_onsets,2) # in seconds\n",
    "    drums_onsets = np.round(drums_onsets/0.01,0) # in samples\n",
    "\n",
    "    \n",
    "    # magenta pitch to model pitch (map to 8 voices)\n",
    "    magenta_mapping = { # [key, [pitches]]\n",
    "        \"kick\":[0,[36]],\n",
    "        \"snare\":[1,[38,40,37]],\n",
    "        \"crash\":[2,[49,55,57,52]],\n",
    "        \"ride\":[3,[51,59,53]],\n",
    "        \"open_hh\":[4,[46,26]],\n",
    "        \"closed_hh\":[5,[42,22,44]],\n",
    "        \"low_mid_tom\":[6,[45,47]],\n",
    "        \"high_tom\":[7,[48,50]]\n",
    "        }\n",
    "    \n",
    "    # initiate magenta_transcription matrix with zeros\n",
    "    magenta_transcription = np.zeros([length_in_samples,8])\n",
    "\n",
    "    # fill magenta_transcription with onsets info\n",
    "    for onset,inst in zip(drums_onsets,drums_instrument):\n",
    "        onset = int(onset)\n",
    "    \n",
    "        # map pretty_midi pitch to magenta pitch value\n",
    "        for magenta_inst in magenta_mapping.keys():\n",
    "        \n",
    "            if inst in magenta_mapping[magenta_inst][1]:\n",
    "                magenta_transcription[onset][magenta_mapping[magenta_inst][0]] = 1\n",
    "    \n",
    "    return magenta_transcription\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_eval_dir = 'threshold_eval/'\n",
    "\n",
    "if not os.path.exists(threshold_eval_dir):\n",
    "    os.mkdir(threshold_eval_dir)\n",
    "    \n",
    "threshold_candidates = np.arange(0.01, 0.3, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pelinski/opt/anaconda3/envs/rhythm/lib/python2.7/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out = out_full[ind]\n",
      "/Users/pelinski/opt/anaconda3/envs/rhythm/lib/python2.7/site-packages/mir_eval/onset.py:49: UserWarning: Reference onsets are empty.\n",
      "  warnings.warn(\"Reference onsets are empty.\")\n",
      "/Users/pelinski/opt/anaconda3/envs/rhythm/lib/python2.7/site-packages/mir_eval/onset.py:51: UserWarning: Estimated onsets are empty.\n",
      "  warnings.warn(\"Estimated onsets are empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10%\n",
      "20%\n",
      "30%\n",
      "40%\n",
      "50%\n",
      "60%\n",
      "70%\n",
      "80%\n",
      "90%\n",
      "100%\n"
     ]
    }
   ],
   "source": [
    "run = True # change to true to run\n",
    "\n",
    "# randomly select 20 files from beat performances\n",
    "audio_files_list = np.array(magenta_ds[magenta_ds['beat_type']=='beat']['audio_filename'])\n",
    "audio_files_list = np.random.choice(audio_files_list, 20)\n",
    "\n",
    "num_performances = len(audio_files_list)\n",
    "num_instruments = 8\n",
    "\n",
    "for performance_idx in range(num_performances):\n",
    "    \n",
    "    if run==False:\n",
    "        break\n",
    "        \n",
    "    # print percentage done\n",
    "    percentage = (performance_idx+1) * 100  / num_performances\n",
    "    if percentage % 10 == 0:\n",
    "        print(str(percentage) + '%')\n",
    "    \n",
    "    # get audio and midi file path\n",
    "    audio_file = os.path.join(groove_path, audio_files_list[performance_idx])\n",
    "    midi_file = os.path.join(groove_path, audio_files_list[performance_idx].split('.')[-2] + '.mid')\n",
    "\n",
    "    \n",
    "    # csv_path\n",
    "    csv_path = os.path.join(threshold_eval_dir,'-'.join(audio_file.split('.')[-2].split('/')[1:])+'.csv')\n",
    "    \n",
    "    # if csv file already exists, jump to next file\n",
    "    if os.path.isfile(csv_path):\n",
    "        continue\n",
    "    \n",
    "    # get magenta onsets \n",
    "    magenta_onsets = get_magenta_onsets(midi_file)\n",
    "    # get model onsets\n",
    "    model_onsets = get_model_onsets(audio_file)\n",
    "    \n",
    "    \n",
    "    # compute scores for each threshold_candidate and instrument and store them in dataframe\n",
    "    df = pd.DataFrame(columns=['threshold','f_measure','instrument_idx'])\n",
    "\n",
    "    \n",
    "    for thres in threshold_candidates:\n",
    "        \n",
    "        out_8v_thres = np.array(model_onsets)\n",
    "        out_8v_thres[out_8v_thres < thres] = 0\n",
    "        out_8v_thres[out_8v_thres > 0] = 1\n",
    "        \n",
    "        for instrument_idx in range(num_instruments):\n",
    "            f_measure,_,_ = compute_scores(magenta_onsets, out_8v_thres,instrument_idx)\n",
    "            \n",
    "            df = df.append({'threshold':thres,\n",
    "                        'f_measure':f_measure,\n",
    "                        'instrument_idx':instrument_idx\n",
    "                           }, ignore_index=True)     \n",
    "\n",
    "    # remove rows with instruments that do not appear\n",
    "    df = df.replace(0, np.nan)\n",
    "    df = df.dropna()\n",
    "    idx = df.groupby(['instrument_idx'])['f_measure'].transform(max) == df['f_measure']\n",
    "    df = df[idx].set_index('instrument_idx')\n",
    "    \n",
    "    # store data to csv\n",
    "    df.to_csv(csv_path, index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrument_idx</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                threshold\n",
       "instrument_idx           \n",
       "1                    0.29\n",
       "2                    0.13\n",
       "3                    0.26\n",
       "4                    0.29\n",
       "5                    0.08\n",
       "6                    0.27\n",
       "7                    0.22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# best value by instrument \n",
    "csv_files = os.listdir(threshold_eval_dir)\n",
    "\n",
    "df_total = pd.DataFrame()\n",
    "\n",
    "for idx,f in enumerate(csv_files):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    file_path = os.path.join(threshold_eval_dir,f)    \n",
    "    df = df.append(pd.read_csv(file_path),ignore_index=True)\n",
    "\n",
    "    # if threshold values gave same f_measure, take min\n",
    "    if 'instrument_idx' in df.columns:\n",
    "        idx = df.groupby(['instrument_idx'])['threshold'].transform(min) == df['threshold']\n",
    "        df = df[idx]\n",
    "    \n",
    "    # remove nan column\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "        \n",
    "    df_total = df_total.append(df)\n",
    "    \n",
    "df = df.astype({'instrument_idx':int})\n",
    "df = df.drop(columns=['f_measure'])\n",
    "df = df.groupby(['instrument_idx']).mean()\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.08, 1: 0.29, 2: 0.13, 3: 0.26, 4: 0.29, 5: 0.08, 6: 0.27, 7: 0.22}\n"
     ]
    }
   ],
   "source": [
    "threshold = {\n",
    "    0: 0,\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "    4: 0,\n",
    "    5: 0,\n",
    "    6: 0,\n",
    "    7: 0\n",
    "}\n",
    "\n",
    "for idx,instrument in enumerate(list(df.index.values)):\n",
    "    threshold[instrument] = np.round(df.iloc[idx]['threshold'],2)\n",
    "\n",
    "#instruments with no threshold optimized get the lowest threshold\n",
    "for instrument in threshold.keys():\n",
    "    if threshold[instrument] == 0:\n",
    "        threshold[instrument] = np.round(df.min()['threshold'],2)\n",
    "\n",
    "print(threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/291\n",
      "['291_drummer5-eval_session-5_funk-groove5_84_beat_4-4.json', '291_drummer7-session1-18_hiphop_100_beat_4-4.json', '291_drummer7-session1-14_jazz_100_beat_4-4.json', '291_drummer3-session2-12_rock_100_beat_4-4.json', '291_drummer8-session1-13_latin_118_beat_4-4.json', '291_drummer7-session3-22_pop-soft_83_beat_4-4.json', '291_drummer8-session1-14_hiphop_94_beat_4-4.json', '291_drummer8-session1-6_funk_80_beat_4-4.json', '291_drummer5-session1-10_latin-brazilian-sambareggae_96_beat_4-4.json', '291_drummer7-session2-97_pop_142_beat_4-4.json', '291_drummer5-session1-8_latin-venezuelan-merengue_162_beat_5-8.json', '291_drummer7-session3-67_neworleans-funk_93_beat_4-4.json', '291_drummer1-session3-6_dance-disco_120_beat_4-4.json']\n",
      "444\n"
     ]
    }
   ],
   "source": [
    "eval_model_dir = 'eval_model'\n",
    "if not os.path.exists(eval_model_dir):\n",
    "    os.mkdir(eval_model_dir)\n",
    "\n",
    "selected_models = [291, 295]\n",
    "results_dir = 'results'\n",
    "\n",
    "# list files in results folders\n",
    "computed_files = os.listdir(os.path.join(results_dir, str(selected_models[0]) ))\n",
    "print(computed_files)\n",
    "\n",
    "num_instruments = 8\n",
    "print(num_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drummer5-eval_session-5_funk-groove5_84_beat_4-4.json\n"
     ]
    }
   ],
   "source": [
    "f = os.path.join(os.path.join(results_dir, str(selected_models[0]) ),\n",
    "                 '291_drummer5-eval_session-5_funk-groove5_84_beat_4-4.json')\n",
    "\n",
    "performance_name = '_'.join(f.split('_')[1:])\n",
    "print(performance_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b992ee7f1907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# compute evaluation scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mf_measure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagenta_onsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_8v_thres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minstrument_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m#save in datatrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eea4fbad098a>\u001b[0m in \u001b[0;36mcompute_scores\u001b[0;34m(magenta_transcription, out_8v_thres, instrument_index)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagenta_transcription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_8v_thres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minstrument_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0monsets_eval_magenta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagenta_transcription\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmagenta_transcription\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minstrument_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0monsets_eval_magenta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monsets_eval_magenta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0monsets_eval_magenta\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "selected_models = [291, 295]\n",
    "thres = {0: 0.04, 1: 0.08, 2: 0.04, 3: 0.04, 4: 0.04, 5: 0.05, 6: 0.04, 7: 0.04}\n",
    "    \n",
    "for model in selected_models:\n",
    "    \n",
    "    # path for storing model results\n",
    "    model_dir = os.path.join(eval_model_dir, str(model))\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "        \n",
    "    file_name = str(model) + '_' + performance_name\n",
    "    file_path = f\n",
    "    result_path = os.path.join(model_dir,file_name)\n",
    "    \n",
    "    with open(file_path) as json_file:\n",
    "        result = json.load(json_file)\n",
    "    \n",
    "    magenta_onsets = result['magenta_onsets']\n",
    "    model_onsets = result['model_onsets']\n",
    "    \n",
    "    \n",
    "    csv_eval_path =  os.path.join(model_dir,\n",
    "                                      file_name.split('.')[-2]+'.csv')\n",
    "    \n",
    "    # compute scores for each threshold_candidate and instrument and store them in dataframe\n",
    "    df = pd.DataFrame(columns=['threshold','f_measure','precision','recall','instrument_idx'])\n",
    "    \n",
    "    for instrument_idx in range(num_instruments):  \n",
    "            \n",
    "            # 0 if < threshold, 1 if > threshold\n",
    "            out_8v_thres = np.array(model_onsets)\n",
    "            out_8v_thres[out_8v_thres < thres[instrument_idx]] = 0\n",
    "            out_8v_thres[out_8v_thres > 0] = 1\n",
    "            \n",
    "            # compute evaluation scores\n",
    "            f_measure,precision,recall = compute_scores(magenta_onsets, out_8v_thres,instrument_idx)\n",
    "            \n",
    "            #save in datatrame\n",
    "            df = df.append({'threshold':thres,\n",
    "                            'f_measure':f_measure,\n",
    "                            'precision':precision,\n",
    "                            'recall':recall,\n",
    "                            'instrument_idx':instrument_idx\n",
    "                           }, ignore_index=True)   \n",
    "\n",
    "    # remove rows with instruments that do not appear\n",
    "    df = df.replace(0, np.nan)\n",
    "    df = df.dropna()\n",
    "    idx = df.groupby(['instrument_idx'])['f_measure'].transform(max) == df['f_measure']\n",
    "    df = df[idx].set_index('instrument_idx')\n",
    "    \n",
    "    # store data to csv\n",
    "    df.to_csv(csv_path, index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291_results/291/291_drummer5-eval_session-5_funk-groove5_84_beat_4-4.json\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'audio_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-789e69d60bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         csv_eval_path =  os.path.join(eval_model_dir,\n\u001b[0;32m---> 50\u001b[0;31m                                       'eval-'+'-'.join(audio_file.split('.')[-2].split('/')[1:])+'.json')\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# compute scores for each threshold_candidate and instrument and store them in dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'audio_file' is not defined"
     ]
    }
   ],
   "source": [
    "selected_models = [291, 295]\n",
    "    \n",
    "for model in selected_models:\n",
    "    \n",
    "    # path for storing model results\n",
    "    model_dir = os.path.join(eval_model_dir, str(model))\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "        \n",
    "    file_name = str(model) + '_' + f\n",
    "    \n",
    "    print(file_name)\n",
    "    \n",
    "    \n",
    "    for performance_idx in range(num_performances):\n",
    "    \n",
    "        \"\"\"\n",
    "        # dev\n",
    "        #if performance_idx>0:\n",
    "        #    break\n",
    "        \n",
    "        # print percentage done\n",
    "        percentage = (performance_idx+1) * 100  / num_performances\n",
    "        if percentage % 10 == 0:\n",
    "            print(str(percentage) + '%')\n",
    "    \n",
    "        # get audio and midi file path\n",
    "        audio_file = os.path.join(groove_path, audio_files_list[performance_idx])\n",
    "        midi_file = os.path.join(groove_path, audio_files_list[performance_idx].split('.')[-2] + '.mid')\n",
    "\n",
    "    \n",
    "        # model_results_json_path\n",
    "        results_json_path = os.path.join(model_dir,'-'.join(audio_file.split('.')[-2].split('/')[1:])+'.json')\n",
    "    \n",
    "        # if csv file already exists do not compute again\n",
    "        if not os.path.isfile(results_json_path):\n",
    "            # get magenta onsets \n",
    "            magenta_onsets = get_magenta_onsets(midi_file)\n",
    "            # get model onsets\n",
    "            model_onsets = get_model_onsets(audio_file,model=model)\n",
    "            results = {'magenta_onsets': magenta_onsets,\n",
    "                       'model_onsets': model_onsets}\n",
    "        \n",
    "            with open(results_json_path, \"w\") as outfile:  \n",
    "                json.dump(results, outfile,default=default) \n",
    "        \"\"\"\n",
    "        \n",
    "        csv_eval_path =  os.path.join(eval_model_dir,\n",
    "                                      'eval-'+'-'.join(audio_file.split('.')[-2].split('/')[1:])+'.json')\n",
    "            \n",
    "        # compute scores for each threshold_candidate and instrument and store them in dataframe\n",
    "        df = pd.DataFrame(columns=['threshold','f_measure','precision','recall','instrument_idx'])\n",
    "        \n",
    "        for instrument_idx in range(num_instruments):       \n",
    "            out_8v_thres = np.array(model_onsets)\n",
    "            out_8v_thres[out_8v_thres < thres[instrument_idx]] = 0\n",
    "            out_8v_thres[out_8v_thres > 0] = 1\n",
    "            f_measure,precision,recall = compute_scores(magenta_transcription, out_8v_thres,instrument_idx)\n",
    "            \n",
    "            df = df.append({'threshold':thres,\n",
    "                            'f_measure':f_measure,\n",
    "                            'precision':precision,\n",
    "                            'recall':recall,\n",
    "                            'instrument_idx':instrument_idx\n",
    "                           }, ignore_index=True)   \n",
    "\n",
    "        # remove rows with instruments that do not appear\n",
    "        df = df.replace(0, np.nan)\n",
    "        df = df.dropna()\n",
    "        idx = df.groupby(['instrument_idx'])['f_measure'].transform(max) == df['f_measure']\n",
    "        df = df[idx].set_index('instrument_idx')\n",
    "    \n",
    "        # store data to csv\n",
    "        df.to_csv(csv_path, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rhythm",
   "language": "python",
   "name": "rhtyhm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
