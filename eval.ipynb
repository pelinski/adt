{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mir_eval\n",
    "\n",
    "def compute_scores(magenta_transcription, out_8v_thres,instrument_index):\n",
    "\n",
    "    onsets_eval_magenta = np.arange(magenta_transcription.shape[0])*magenta_transcription[:,instrument_index]*0.01 \n",
    "    onsets_eval_magenta = np.sort(onsets_eval_magenta[onsets_eval_magenta!=0])\n",
    "\n",
    "    onsets_eval_model = np.arange(out_8v_thres.shape[0])*out_8v_thres[:,instrument_index]*0.01\n",
    "    onsets_eval_model = np.sort(onsets_eval_model[onsets_eval_model!=0])\n",
    "\n",
    "\n",
    "    #print(onsets_eval_magenta[0:5])\n",
    "    #print(np.round(onsets_eval_model[0:5],2))\n",
    "    #print(len(onsets_eval_model),len(onsets_eval_magenta))\n",
    "\n",
    "    # mir_eval: \n",
    "    # Onsets should be provided in the form of a 1-dimensional array of onset \n",
    "    # times in seconds in increasing order.\n",
    "    # default window is 0.05 seconds !! CHOICE OF WINDOW IS CRUCIAL\n",
    "    # same value as in paper\n",
    "    mir_eval.onset.validate(onsets_eval_magenta,onsets_eval_model)\n",
    "    scores = mir_eval.onset.f_measure(onsets_eval_magenta,onsets_eval_model, window=0.5)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/291\n",
      "['291_drummer5-eval_session-5_funk-groove5_84_beat_4-4.json', '291_drummer7-session1-18_hiphop_100_beat_4-4.json', '291_drummer7-session1-14_jazz_100_beat_4-4.json', '291_drummer3-session2-12_rock_100_beat_4-4.json', '291_drummer8-session1-13_latin_118_beat_4-4.json', '291_drummer7-session3-22_pop-soft_83_beat_4-4.json', '291_drummer8-session1-14_hiphop_94_beat_4-4.json', '291_drummer8-session1-6_funk_80_beat_4-4.json', '291_drummer5-session1-10_latin-brazilian-sambareggae_96_beat_4-4.json', '291_drummer7-session2-97_pop_142_beat_4-4.json', '291_drummer5-session1-8_latin-venezuelan-merengue_162_beat_5-8.json', '291_drummer7-session3-67_neworleans-funk_93_beat_4-4.json', '291_drummer1-session3-6_dance-disco_120_beat_4-4.json']\n",
      "444\n"
     ]
    }
   ],
   "source": [
    "eval_model_dir = 'eval_model'\n",
    "if not os.path.exists(eval_model_dir):\n",
    "    os.mkdir(eval_model_dir)\n",
    "\n",
    "selected_models = [291, 295]\n",
    "results_dir = 'results'\n",
    "\n",
    "# list files in results folders\n",
    "computed_files = os.listdir(os.path.join(results_dir, str(selected_models[0]) ))\n",
    "print(computed_files)\n",
    "\n",
    "num_instruments = 8\n",
    "print(num_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drummer5-eval_session-5_funk-groove5_84_beat_4-4.json\n"
     ]
    }
   ],
   "source": [
    "f = os.path.join(os.path.join(results_dir, str(selected_models[0]) ),\n",
    "                 '291_drummer5-eval_session-5_funk-groove5_84_beat_4-4.json')\n",
    "\n",
    "performance_name = '_'.join(f.split('_')[1:])\n",
    "print(performance_name)\n",
    "\n",
    "\n",
    "for model in selected_models:\n",
    "    eval_model_dir = os.path.join(eval_model_dir, str(model))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ae28aeb275fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         csv_eval_path =  os.path.join(eval_model_dir,\n\u001b[0;32m---> 45\u001b[0;31m                                       'eval-'+'-'.join(audio_file.split('.')[-2].split('/')[1:])+'.json')\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# compute scores for each threshold_candidate and instrument and store them in dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'audio_file' is not defined"
     ]
    }
   ],
   "source": [
    "selected_models = [291, 295]\n",
    "    \n",
    "for model in selected_models:\n",
    "    \n",
    "    # path for storing model results\n",
    "    model_dir = os.path.join(eval_model_dir, str(model))\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    for performance_idx in range(num_performances):\n",
    "    \n",
    "        \"\"\"\n",
    "        # dev\n",
    "        #if performance_idx>0:\n",
    "        #    break\n",
    "        \n",
    "        # print percentage done\n",
    "        percentage = (performance_idx+1) * 100  / num_performances\n",
    "        if percentage % 10 == 0:\n",
    "            print(str(percentage) + '%')\n",
    "    \n",
    "        # get audio and midi file path\n",
    "        audio_file = os.path.join(groove_path, audio_files_list[performance_idx])\n",
    "        midi_file = os.path.join(groove_path, audio_files_list[performance_idx].split('.')[-2] + '.mid')\n",
    "\n",
    "    \n",
    "        # model_results_json_path\n",
    "        results_json_path = os.path.join(model_dir,'-'.join(audio_file.split('.')[-2].split('/')[1:])+'.json')\n",
    "    \n",
    "        # if csv file already exists do not compute again\n",
    "        if not os.path.isfile(results_json_path):\n",
    "            # get magenta onsets \n",
    "            magenta_onsets = get_magenta_onsets(midi_file)\n",
    "            # get model onsets\n",
    "            model_onsets = get_model_onsets(audio_file,model=model)\n",
    "            results = {'magenta_onsets': magenta_onsets,\n",
    "                       'model_onsets': model_onsets}\n",
    "        \n",
    "            with open(results_json_path, \"w\") as outfile:  \n",
    "                json.dump(results, outfile,default=default) \n",
    "        \"\"\"\n",
    "        \n",
    "        csv_eval_path =  os.path.join(eval_model_dir,\n",
    "                                      'eval-'+'-'.join(audio_file.split('.')[-2].split('/')[1:])+'.json')\n",
    "            \n",
    "        # compute scores for each threshold_candidate and instrument and store them in dataframe\n",
    "        df = pd.DataFrame(columns=['threshold','f_measure','precision','recall','instrument_idx'])\n",
    "        \n",
    "        for instrument_idx in range(num_instruments):       \n",
    "            out_8v_thres = np.array(model_onsets)\n",
    "            out_8v_thres[out_8v_thres < thres[instrument_idx]] = 0\n",
    "            out_8v_thres[out_8v_thres > 0] = 1\n",
    "            f_measure,precision,recall = compute_scores(magenta_transcription, out_8v_thres,instrument_idx)\n",
    "            \n",
    "            df = df.append({'threshold':thres,\n",
    "                            'f_measure':f_measure,\n",
    "                            'precision':precision,\n",
    "                            'recall':recall,\n",
    "                            'instrument_idx':instrument_idx\n",
    "                           }, ignore_index=True)   \n",
    "\n",
    "        # remove rows with instruments that do not appear\n",
    "        df = df.replace(0, np.nan)\n",
    "        df = df.dropna()\n",
    "        idx = df.groupby(['instrument_idx'])['f_measure'].transform(max) == df['f_measure']\n",
    "        df = df[idx].set_index('instrument_idx')\n",
    "    \n",
    "        # store data to csv\n",
    "        df.to_csv(csv_path, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rhythm",
   "language": "python",
   "name": "rhtyhm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
